From patchwork Tue Jun  4 20:33:13 2019
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 8bit
X-Patchwork-Submitter: Eugene Korenevsky <ekorenevsky@gmail.com>
X-Patchwork-Id: 10976015
Return-Path: <kvm-owner@kernel.org>
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
 [172.30.200.125])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id 4B24F76
	for <patchwork-kvm@patchwork.kernel.org>;
 Tue,  4 Jun 2019 20:33:22 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 3A4C820587
	for <patchwork-kvm@patchwork.kernel.org>;
 Tue,  4 Jun 2019 20:33:22 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 2C3A6286B9; Tue,  4 Jun 2019 20:33:22 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-8.0 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID,DKIM_VALID_AU,FREEMAIL_FROM,MAILING_LIST_MULTI,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 9A925286B9
	for <patchwork-kvm@patchwork.kernel.org>;
 Tue,  4 Jun 2019 20:33:21 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1726352AbfFDUdU (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Tue, 4 Jun 2019 16:33:20 -0400
Received: from mail-lf1-f65.google.com ([209.85.167.65]:46451 "EHLO
        mail-lf1-f65.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1726033AbfFDUdU (ORCPT <rfc822;kvm@vger.kernel.org>);
        Tue, 4 Jun 2019 16:33:20 -0400
Received: by mail-lf1-f65.google.com with SMTP id l26so17416950lfh.13
        for <kvm@vger.kernel.org>; Tue, 04 Jun 2019 13:33:18 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20161025;
        h=date:from:to:cc:subject:message-id:mail-followup-to:mime-version
         :content-disposition:content-transfer-encoding:user-agent;
        bh=+qR7k4fQsvJSOTG1+GHIY0O5I4zb3htSI7DgZU8DKKc=;
        b=U2cND/4zpnbsJRsxkSQGEwPEbllRyG9TUYAjNs1Uhr/rNnxS4tfqTymzxBnA5F5v6B
         9/M6YF+gZrXqYvpPb55rQIega6czqVrSsq3cfF6T8tm+YN7tu8NH9q1vlZW65xuLkn3C
         Fh8qrY1/cFU3Q2nKyvlloEGiCmOdN+2OMjhgRGujory+ehdWsYDds/T7f6UIExC1djBf
         /MpB/tvE0FLnmdAIrTErbxGeAvtIZI/6OsDmdOiF4pDjo4PQf6PP6+1q3hdcjsZt0kZf
         L+IKwF55c0iDtf33IaopLG8HTMOCrk7q350mdIC7CZMmJuSRoNrA6j5BSIDyM31iKkmX
         noyA==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:date:from:to:cc:subject:message-id
         :mail-followup-to:mime-version:content-disposition
         :content-transfer-encoding:user-agent;
        bh=+qR7k4fQsvJSOTG1+GHIY0O5I4zb3htSI7DgZU8DKKc=;
        b=tXf1y7pPn0KJPB7EECeRMYL66SVR8LaE+TUtZxppznSEoPWthCMRUDaK7a+lWwu3OP
         NcQc1IJc4Ewd8bmguyuwBF2R4uaDbQHeV04LVCjGNTdwXeniMO4dU5Tlh84hmkWuYyo4
         OXG0D3IvmnxR8wi6z2Jwc5YAiQwWk48yoWebpA9WHoRnCI6Vb1enwIVPtmugshAluLoT
         PM8ymFK3FYog28PsHp/6xwDcmYaTmwAIfGDm9dAnGrw6lASP7lY9Ta2LsvK6cKKY1/41
         GwTOkdQMQY9Il0jZIg6VOs2IJpb4TapANk498tusHIm22WS7TkWqCE6H8xdkHbwAMLuB
         QKAg==
X-Gm-Message-State: APjAAAWBjvHf8ntdxJDl7g7f5DlHxtB8xAVcIcW8kFOEE/U1JSB38B54
        rkLAzKBr071x/SDAt4bMj4Bb3DrX
X-Google-Smtp-Source: 
 APXvYqzoOy2/43z16voJp8F9tNIkp16qxzOJ31WFvx+H1/qplErzOTJi7jnuzcn+x5Fryi/nAr912g==
X-Received: by 2002:ac2:424b:: with SMTP id
 m11mr17021647lfl.163.1559680397703;
        Tue, 04 Jun 2019 13:33:17 -0700 (PDT)
Received: from dnote ([5.35.65.245])
        by smtp.gmail.com with ESMTPSA id
 y4sm3968646lje.24.2019.06.04.13.33.16
        (version=TLS1_2 cipher=ECDHE-RSA-CHACHA20-POLY1305 bits=256/256);
        Tue, 04 Jun 2019 13:33:16 -0700 (PDT)
Date: Tue, 4 Jun 2019 23:33:13 +0300
From: Eugene Korenevsky <ekorenevsky@gmail.com>
To: kvm@vger.kernel.org
Cc: Paolo Bonzini <pbonzini@redhat.com>
Subject: [PATCH 1/2] kvm: vmx: fix limit checking in get_vmx_mem_address()
Message-ID: <20190604203313.GA7215@dnote>
Mail-Followup-To: Eugene Korenevsky <ekorenevsky@gmail.com>,
        kvm@vger.kernel.org, Paolo Bonzini <pbonzini@redhat.com>
MIME-Version: 1.0
Content-Type: text/plain; charset=utf-8
Content-Disposition: inline
User-Agent: Mutt/1.12.0 (2019-05-25)
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP

Intel SDM vol. 3, 5.3:
The processor causes a
general-protection exception (or, if the segment is SS, a stack-fault
exception) any time an attempt is made to access the following addresses
in a segment:
- A byte at an offset greater than the effective limit
- A word at an offset greater than the (effective-limit – 1)
- A doubleword at an offset greater than the (effective-limit – 3)
- A quadword at an offset greater than the (effective-limit – 7)

Therefore, the generic limit checking error condition must be

exn = off > limit + 1 - operand_len

but not

exn = off + operand_len > limit

as for now.

Signed-off-by: Eugene Korenevsky <ekorenevsky@gmail.com>
---
 arch/x86/kvm/vmx/nested.c | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/arch/x86/kvm/vmx/nested.c b/arch/x86/kvm/vmx/nested.c
index f1a69117ac0f..fef3d7031715 100644
--- a/arch/x86/kvm/vmx/nested.c
+++ b/arch/x86/kvm/vmx/nested.c
@@ -4115,7 +4115,7 @@ int get_vmx_mem_address(struct kvm_vcpu *vcpu, unsigned long exit_qualification,
 		 */
 		if (!(s.base == 0 && s.limit == 0xffffffff &&
 		     ((s.type & 8) || !(s.type & 4))))
-			exn = exn || (off + sizeof(u64) > s.limit);
+			exn = exn || (off > s.limit + 1 - sizeof(u64));
 	}
 	if (exn) {
 		kvm_queue_exception_e(vcpu,

From patchwork Tue Jun  4 20:34:29 2019
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Eugene Korenevsky <ekorenevsky@gmail.com>
X-Patchwork-Id: 10976019
Return-Path: <kvm-owner@kernel.org>
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
 [172.30.200.125])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id D87BA76
	for <patchwork-kvm@patchwork.kernel.org>;
 Tue,  4 Jun 2019 20:34:37 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id C62CF28643
	for <patchwork-kvm@patchwork.kernel.org>;
 Tue,  4 Jun 2019 20:34:37 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id BA9E2288CE; Tue,  4 Jun 2019 20:34:37 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-8.0 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID,DKIM_VALID_AU,FREEMAIL_FROM,MAILING_LIST_MULTI,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 0714C288CA
	for <patchwork-kvm@patchwork.kernel.org>;
 Tue,  4 Jun 2019 20:34:37 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1726463AbfFDUef (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Tue, 4 Jun 2019 16:34:35 -0400
Received: from mail-lj1-f196.google.com ([209.85.208.196]:44765 "EHLO
        mail-lj1-f196.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1726033AbfFDUef (ORCPT <rfc822;kvm@vger.kernel.org>);
        Tue, 4 Jun 2019 16:34:35 -0400
Received: by mail-lj1-f196.google.com with SMTP id p67so4556094ljp.11
        for <kvm@vger.kernel.org>; Tue, 04 Jun 2019 13:34:33 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20161025;
        h=date:from:to:cc:subject:message-id:mail-followup-to:mime-version
         :content-disposition:user-agent;
        bh=aC+VyuT2MVroQSKKJWYDMpZnJSbkZpk92/nd9PY2jq0=;
        b=mUssyxo1D3uiA5Ej9BbAwVYBv6adyfPVwZUnYZ/cl7jOegrEec29K+GGIuOFROY+DA
         DGltVFSPkW/McbkDZ2JbCpQs9514RgeyYcMYv5K5OwXYzQXUblvcc0eKiaK2ByVvp8lW
         l0I4SSfPA8PmPKQUFmEMvvH6ueurHYPA08TccNEu4/ywXPyBy26AtHpSboqV0hWj5M5l
         vMYDaAdoCaNrFcmBhkUDsEh0t79+2ETcVslU5gLyQLTJQc2wZCcAb78J/GmikAZqi+NX
         O5TPG0FiYJA+TZ3iH7/u8uwn/6C6gXbiezSVo7WRMdTO3PwyW7neXSwiVjfgpvF2te+n
         POBw==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:date:from:to:cc:subject:message-id
         :mail-followup-to:mime-version:content-disposition:user-agent;
        bh=aC+VyuT2MVroQSKKJWYDMpZnJSbkZpk92/nd9PY2jq0=;
        b=OouyG7lvVunOpqZwvm4UMZ+gGbEGMJZW7T6LTdbqTGNFF09CWC9n9YQeNVhlH/eBOH
         rPs2U9ctzo61o7ESrjVCpcpJmy0NIW0yGVjx67uJHw2X6aBzCL34B6LSGcBnlhk+4egJ
         6wM2p+AvedS8NXuoFIQeZHqx+E84430xOiHoQADYIBDqjhZUHf5CDKQDqe+J5dho4KeD
         yUfWhfH2+9EvyH2pxWUk3D4wJ4rsYZamHNC39v4ACMF3Cc8OHn3Qq/sQ/czyG1hokQr3
         8GeVbsRYl2zTmrsu0hfwBVLthWK5svFhkyIMPKOkV2v7z28qpiAb0h3XwvNysjBqEqaS
         NZJg==
X-Gm-Message-State: APjAAAVmv0p5GjXZmy8UyBRaUPxoFQ6/ZlwWvCyGcj+3TxzmCNBb790U
        J9s2BPLc7c2MSo4FqNq0gZv4x4wI
X-Google-Smtp-Source: 
 APXvYqyJbMVBYlkhW3CS4kDlIWeYv4vwIYHdhFTmqiqbFJEq7Gp9RHDMllsK/66w+KByGxOnMYA6bg==
X-Received: by 2002:a2e:9255:: with SMTP id
 v21mr10998256ljg.178.1559680472625;
        Tue, 04 Jun 2019 13:34:32 -0700 (PDT)
Received: from dnote ([5.35.65.245])
        by smtp.gmail.com with ESMTPSA id
 m25sm2897925lfp.97.2019.06.04.13.34.31
        (version=TLS1_2 cipher=ECDHE-RSA-CHACHA20-POLY1305 bits=256/256);
        Tue, 04 Jun 2019 13:34:32 -0700 (PDT)
Date: Tue, 4 Jun 2019 23:34:29 +0300
From: Eugene Korenevsky <ekorenevsky@gmail.com>
To: kvm@vger.kernel.org
Cc: Paolo Bonzini <pbonzini@redhat.com>
Subject: [PATCH 2/2] kvm: vmx: take access length into account when checking
 the limit
Message-ID: <20190604203429.GA15407@dnote>
Mail-Followup-To: Eugene Korenevsky <ekorenevsky@gmail.com>,
        kvm@vger.kernel.org, Paolo Bonzini <pbonzini@redhat.com>
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
User-Agent: Mutt/1.12.0 (2019-05-25)
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP

There is an imperfection in get_vmx_mem_address(): access length is ignored
when checking the limit. To fix this, pass access length as a function argument.
The access length is obvious since it is used by callers after
get_vmx_mem_address() call.

Signed-off-by: Eugene Korenevsky <ekorenevsky@gmail.com>
---
 arch/x86/kvm/vmx/nested.c | 26 +++++++++++++++-----------
 arch/x86/kvm/vmx/nested.h |  2 +-
 arch/x86/kvm/vmx/vmx.c    |  3 ++-
 3 files changed, 18 insertions(+), 13 deletions(-)

diff --git a/arch/x86/kvm/vmx/nested.c b/arch/x86/kvm/vmx/nested.c
index fef3d7031715..7c0fadfaa155 100644
--- a/arch/x86/kvm/vmx/nested.c
+++ b/arch/x86/kvm/vmx/nested.c
@@ -4008,7 +4008,7 @@ void nested_vmx_vmexit(struct kvm_vcpu *vcpu, u32 exit_reason,
  * #UD or #GP.
  */
 int get_vmx_mem_address(struct kvm_vcpu *vcpu, unsigned long exit_qualification,
-			u32 vmx_instruction_info, bool wr, gva_t *ret)
+			u32 vmx_instruction_info, bool wr, int len, gva_t *ret)
 {
 	gva_t off;
 	bool exn;
@@ -4134,7 +4134,8 @@ static int nested_vmx_get_vmptr(struct kvm_vcpu *vcpu, gpa_t *vmpointer)
 	struct x86_exception e;
 
 	if (get_vmx_mem_address(vcpu, vmcs_readl(EXIT_QUALIFICATION),
-			vmcs_read32(VMX_INSTRUCTION_INFO), false, &gva))
+				vmcs_read32(VMX_INSTRUCTION_INFO), false,
+				sizeof(*vmpointer), &gva))
 		return 1;
 
 	if (kvm_read_guest_virt(vcpu, gva, vmpointer, sizeof(*vmpointer), &e)) {
@@ -4386,6 +4387,7 @@ static int handle_vmread(struct kvm_vcpu *vcpu)
 	u64 field_value;
 	unsigned long exit_qualification = vmcs_readl(EXIT_QUALIFICATION);
 	u32 vmx_instruction_info = vmcs_read32(VMX_INSTRUCTION_INFO);
+	int len;
 	gva_t gva = 0;
 	struct vmcs12 *vmcs12;
 
@@ -4423,12 +4425,12 @@ static int handle_vmread(struct kvm_vcpu *vcpu)
 		kvm_register_writel(vcpu, (((vmx_instruction_info) >> 3) & 0xf),
 			field_value);
 	} else {
+		len = is_64_bit_mode(vcpu) ? 8 : 4;
 		if (get_vmx_mem_address(vcpu, exit_qualification,
-				vmx_instruction_info, true, &gva))
+				vmx_instruction_info, true, len, &gva))
 			return 1;
 		/* _system ok, nested_vmx_check_permission has verified cpl=0 */
-		kvm_write_guest_virt_system(vcpu, gva, &field_value,
-					    (is_long_mode(vcpu) ? 8 : 4), NULL);
+		kvm_write_guest_virt_system(vcpu, gva, &field_value, len, NULL);
 	}
 
 	return nested_vmx_succeed(vcpu);
@@ -4438,6 +4440,7 @@ static int handle_vmread(struct kvm_vcpu *vcpu)
 static int handle_vmwrite(struct kvm_vcpu *vcpu)
 {
 	unsigned long field;
+	int len;
 	gva_t gva;
 	struct vcpu_vmx *vmx = to_vmx(vcpu);
 	unsigned long exit_qualification = vmcs_readl(EXIT_QUALIFICATION);
@@ -4463,11 +4466,11 @@ static int handle_vmwrite(struct kvm_vcpu *vcpu)
 		field_value = kvm_register_readl(vcpu,
 			(((vmx_instruction_info) >> 3) & 0xf));
 	else {
+		len = is_64_bit_mode(vcpu) ? 8 : 4;
 		if (get_vmx_mem_address(vcpu, exit_qualification,
-				vmx_instruction_info, false, &gva))
+				vmx_instruction_info, false, len, &gva))
 			return 1;
-		if (kvm_read_guest_virt(vcpu, gva, &field_value,
-					(is_64_bit_mode(vcpu) ? 8 : 4), &e)) {
+		if (kvm_read_guest_virt(vcpu, gva, &field_value, len, &e)) {
 			kvm_inject_page_fault(vcpu, &e);
 			return 1;
 		}
@@ -4615,7 +4618,8 @@ static int handle_vmptrst(struct kvm_vcpu *vcpu)
 	if (unlikely(to_vmx(vcpu)->nested.hv_evmcs))
 		return 1;
 
-	if (get_vmx_mem_address(vcpu, exit_qual, instr_info, true, &gva))
+	if (get_vmx_mem_address(vcpu, exit_qual, instr_info,
+				true, sizeof(gpa_t), &gva))
 		return 1;
 	/* *_system ok, nested_vmx_check_permission has verified cpl=0 */
 	if (kvm_write_guest_virt_system(vcpu, gva, (void *)&current_vmptr,
@@ -4661,7 +4665,7 @@ static int handle_invept(struct kvm_vcpu *vcpu)
 	 * operand is read even if it isn't needed (e.g., for type==global)
 	 */
 	if (get_vmx_mem_address(vcpu, vmcs_readl(EXIT_QUALIFICATION),
-			vmx_instruction_info, false, &gva))
+			vmx_instruction_info, false, sizeof(operand), &gva))
 		return 1;
 	if (kvm_read_guest_virt(vcpu, gva, &operand, sizeof(operand), &e)) {
 		kvm_inject_page_fault(vcpu, &e);
@@ -4723,7 +4727,7 @@ static int handle_invvpid(struct kvm_vcpu *vcpu)
 	 * operand is read even if it isn't needed (e.g., for type==global)
 	 */
 	if (get_vmx_mem_address(vcpu, vmcs_readl(EXIT_QUALIFICATION),
-			vmx_instruction_info, false, &gva))
+			vmx_instruction_info, false, sizeof(operand), &gva))
 		return 1;
 	if (kvm_read_guest_virt(vcpu, gva, &operand, sizeof(operand), &e)) {
 		kvm_inject_page_fault(vcpu, &e);
diff --git a/arch/x86/kvm/vmx/nested.h b/arch/x86/kvm/vmx/nested.h
index e847ff1019a2..29d205bb4e4f 100644
--- a/arch/x86/kvm/vmx/nested.h
+++ b/arch/x86/kvm/vmx/nested.h
@@ -21,7 +21,7 @@ void nested_sync_from_vmcs12(struct kvm_vcpu *vcpu);
 int vmx_set_vmx_msr(struct kvm_vcpu *vcpu, u32 msr_index, u64 data);
 int vmx_get_vmx_msr(struct nested_vmx_msrs *msrs, u32 msr_index, u64 *pdata);
 int get_vmx_mem_address(struct kvm_vcpu *vcpu, unsigned long exit_qualification,
-			u32 vmx_instruction_info, bool wr, gva_t *ret);
+			u32 vmx_instruction_info, bool wr, int len, gva_t *ret);
 
 static inline struct vmcs12 *get_vmcs12(struct kvm_vcpu *vcpu)
 {
diff --git a/arch/x86/kvm/vmx/vmx.c b/arch/x86/kvm/vmx/vmx.c
index 1ac167614032..6ecf9e4de2f9 100644
--- a/arch/x86/kvm/vmx/vmx.c
+++ b/arch/x86/kvm/vmx/vmx.c
@@ -5342,7 +5342,8 @@ static int handle_invpcid(struct kvm_vcpu *vcpu)
 	 * is read even if it isn't needed (e.g., for type==all)
 	 */
 	if (get_vmx_mem_address(vcpu, vmcs_readl(EXIT_QUALIFICATION),
-				vmx_instruction_info, false, &gva))
+				vmx_instruction_info, false,
+				sizeof(operand), &gva))
 		return 1;
 
 	if (kvm_read_guest_virt(vcpu, gva, &operand, sizeof(operand), &e)) {
