From patchwork Thu Sep  5 17:15:02 2019
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Andre Przywara <andre.przywara@arm.com>
X-Patchwork-Id: 11133703
Return-Path: <SRS0=qAVt=XA=vger.kernel.org=kvm-owner@kernel.org>
Received: from mail.kernel.org (pdx-korg-mail-1.web.codeaurora.org
 [172.30.200.123])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id 11F83112B
	for <patchwork-kvm@patchwork.kernel.org>;
 Thu,  5 Sep 2019 17:15:13 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id 8FE4A20828
	for <patchwork-kvm@patchwork.kernel.org>;
 Thu,  5 Sep 2019 17:15:13 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1732456AbfIERPL (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Thu, 5 Sep 2019 13:15:11 -0400
Received: from foss.arm.com ([217.140.110.172]:47828 "EHLO foss.arm.com"
        rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
        id S1730864AbfIERPL (ORCPT <rfc822;kvm@vger.kernel.org>);
        Thu, 5 Sep 2019 13:15:11 -0400
Received: from usa-sjc-imap-foss1.foss.arm.com (unknown [10.121.207.14])
        by usa-sjc-mx-foss1.foss.arm.com (Postfix) with ESMTP id 80B43337;
        Thu,  5 Sep 2019 10:15:10 -0700 (PDT)
Received: from donnerap.arm.com (donnerap.cambridge.arm.com [10.1.197.44])
        by usa-sjc-imap-foss1.foss.arm.com (Postfix) with ESMTPSA id
 986843F718;
        Thu,  5 Sep 2019 10:15:09 -0700 (PDT)
From: Andre Przywara <andre.przywara@arm.com>
To: Andrew Jones <drjones@redhat.com>
Cc: kvmarm@lists.cs.columbia.edu, kvm@vger.kernel.org,
        Alexandru Elisei <alexandru.elisei@arm.com>,
        Paolo Bonzini <pbonzini@redhat.com>
Subject: [PATCH kvm-unit-tests] arm: prevent compiler from using unaligned
 accesses
Date: Thu,  5 Sep 2019 18:15:02 +0100
Message-Id: <20190905171502.215183-1-andre.przywara@arm.com>
X-Mailer: git-send-email 2.17.1
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org

The ARM architecture requires all accesses to device memory to be
naturally aligned[1][2]. Normal memory does not have this strict
requirement, and in fact many systems do ignore unaligned accesses
(by the means of clearing the A bit in SCTLR and accessing normal
memory). So the default behaviour of GCC assumes that unaligned accesses
are fine, at least if happening on the stack.

Now kvm-unit-tests runs some C code with the MMU off, which degrades the
whole system memory to device memory. Now every unaligned access will
fault, regardless of the A bit.
In fact there is at least one place in lib/printf.c where GCC merges
two consecutive char* accesses into one "strh" instruction, writing to
a potentially unaligned address.
This can be reproduced by configuring kvm-unit-tests for kvmtool, but
running it on QEMU, which triggers an early printf that exercises this
particular code path.

Add the -mstrict-align compiler option to the arm64 CFLAGS to fix this
problem. Also add the respective -mno-unaligned-access flag for arm.

Thanks to Alexandru for helping debugging this.

Signed-off-by: Andre Przywara <andre.przywara@arm.com>

[1] ARMv8 ARM DDI 0487E.a, B2.5.2
[2] ARMv7 ARM DDI 0406C.d, A3.2.1
---
 arm/Makefile.arm   | 1 +
 arm/Makefile.arm64 | 1 +
 2 files changed, 2 insertions(+)

diff --git a/arm/Makefile.arm b/arm/Makefile.arm
index a625267..43b4be1 100644
--- a/arm/Makefile.arm
+++ b/arm/Makefile.arm
@@ -12,6 +12,7 @@ KEEP_FRAME_POINTER := y
 
 CFLAGS += $(machine)
 CFLAGS += -mcpu=$(PROCESSOR)
+CFLAGS += -mno-unaligned-access
 
 arch_LDFLAGS = -Ttext=40010000
 
diff --git a/arm/Makefile.arm64 b/arm/Makefile.arm64
index 02c24e8..35de5ea 100644
--- a/arm/Makefile.arm64
+++ b/arm/Makefile.arm64
@@ -7,6 +7,7 @@ bits = 64
 ldarch = elf64-littleaarch64
 
 arch_LDFLAGS = -pie -n
+CFLAGS += -mstrict-align
 
 define arch_elf_check =
 	$(if $(shell ! $(OBJDUMP) -R $(1) >&/dev/null && echo "nok"),
